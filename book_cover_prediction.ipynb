{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "# import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from getpass import getpass\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from requests.exceptions import HTTPError\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Art-Photography', 'Biography', 'Business-Finance-Law', 'Childrens-Books', 'Computing', 'Crafts-Hobbies', 'Crime-Thriller', 'Dictionaries-Languages', 'Entertainment', 'Food-Drink', 'Graphic-Novels-Anime-Manga', 'Health', 'History-Archaeology', 'Home-Garden', 'Humour', 'Medical', 'Mind-Body-Spirit', 'Natural-History', 'Personal-Development', 'Poetry-Drama', 'Reference', 'Religion', 'Romance', 'Science-Fiction-Fantasy-Horror', 'Science-Geography', 'Society-Social-Sciences', 'Sport', 'Stationery', 'Teaching-Resources-Education', 'Technology-Engineering', 'Teen-Young-Adult', 'Transport', 'Travel-Holiday-Guides']\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path('book_cover_temp')\n",
    "\n",
    "CATEGORIES = next(os.walk(DATA_DIR), (None, None, []))[1]\n",
    "print(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ImageFolder(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# For some reason kernal keep crashing when trying to plot test dataset samples\n",
    "# The sampling code was moved to another notebook\n",
    "\n",
    "# plt.subplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_book_samples(DATA_DIR):\n",
    "#     CATEGORIES = next(os.walk(DATA_DIR), (None, None, []))[1]\n",
    "#     num_examples_per_class = 3\n",
    "#     f, axes = plt.subplots(nrows=len(CATEGORIES), ncols=num_examples_per_class)\n",
    "\n",
    "#     axes = axes.ravel()\n",
    "#     for classes in os.listdir(DATA_DIR):\n",
    "#         d = os.path.join(DATA_DIR, classes)\n",
    "#         if os.path.isdir(d):\n",
    "#             print(d)\n",
    "#         # for image_idx, image_path in enumerate(sorted(folder.glob('*'))):\n",
    "#         #     if image_path.suffix in ds.extensions:\n",
    "#         #         image = Image.open(image_path)\n",
    "#         #         plt.subplot(len(ds.classes), num_examples_per_class, i)\n",
    "#         #         ax = plt.gca()\n",
    "#         #         ax.set_title(\n",
    "#         #             class_name,\n",
    "#         #             size='xx-large',\n",
    "#         #             pad=5,\n",
    "#         #             loc='left',\n",
    "#         #             y=0,\n",
    "#         #             backgroundcolor='white'\n",
    "#         #         )\n",
    "#         #         ax.axis('off')\n",
    "#         #         plt.imshow(image)\n",
    "#         #         i += 1\n",
    "\n",
    "#         #         if image_idx + 1 == num_examples_per_class:\n",
    "#         #             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# display_book_samples(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {}\n",
    "id2label = {}\n",
    "\n",
    "for i, class_name in enumerate(CATEGORIES):\n",
    "    label2id[class_name] = str(i)\n",
    "    id2label[str(i)] = class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationCollator:\n",
    "    def __init__(self, feature_extractor):\n",
    "        self.feature_extractor = feature_extractor\n",
    " \n",
    "    def __call__(self, batch):\n",
    "        encodings = self.feature_extractor([x[0] for x in batch], return_tensors='pt')\n",
    "        encodings['labels'] = torch.tensor([x[1] for x in batch], dtype=torch.long)\n",
    "        return encodings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('fine_tuned_models')\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'fine_tuned_models',\n",
    "    num_labels=len(label2id),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n",
    "collator = ImageClassificationCollator(feature_extractor)\n",
    "test_loader = DataLoader(test_ds, batch_size=8, collate_fn=collator,  shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, lr: float = 2e-5, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters('lr', *list(kwargs))\n",
    "        self.model = model\n",
    "        self.forward = self.model.forward\n",
    "        self.val_acc = Accuracy()\n",
    "\n",
    "    # def training_step(self, batch, batch_idx):\n",
    "    #     outputs = self(**batch)\n",
    "    #     self.log(f\"train_loss\", outputs.loss)\n",
    "    #     return outputs.loss\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     outputs = self(**batch)\n",
    "    #     self.log(f\"val_loss\", outputs.loss)\n",
    "    #     acc = self.val_acc(outputs.logits.argmax(1), batch['labels'])\n",
    "    #     self.log(f\"val_acc\", acc, prog_bar=True)\n",
    "    #     return outputs.loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        outputs = self(**batch)\n",
    "        self.log(f\"test_loss\", outputs.loss)\n",
    "        acc = self.val_acc(outputs.logits.argmax(1), batch['labels'])\n",
    "        self.log(f\"test_acc\", acc, prog_bar=True)\n",
    "        return outputs.loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "e:\\Program Files\\miniconda3\\envs\\project\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:448: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "e:\\Program Files\\miniconda3\\envs\\project\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:241: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ea410ede2a4c0099fbb63ee46966c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.19685038924217224\n",
      "        test_loss            3.119323253631592\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 3.119323253631592, 'test_acc': 0.19685038924217224}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "classifier = Classifier(model, lr=2e-5)\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "trainer.test(classifier, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(test_loader, model, device_):\n",
    "    # logits = []\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for test_batch in tqdm(test_loader, total=len(test_loader)):\n",
    "        # test_batch = next(iter(test_loader))\n",
    "        true_labels += test_batch['labels'].numpy().flatten().tolist()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**test_batch)\n",
    "            loss, logits = outputs[:2]\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            total_loss += loss.item()\n",
    "            predict_content = logits.argmax(axis=-1).flatten().tolist()\n",
    "            predictions_labels += predict_content\n",
    "    \n",
    "    avg_epoch_loss = total_loss / len(test_loader)\n",
    "        \n",
    "    return true_labels, predictions_labels, avg_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cca9dcf2a34e41a6b9fba7d192ec89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels, predictions_labels, avg_epoch_loss = validation(test_loader,model , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1099701076745987\n"
     ]
    }
   ],
   "source": [
    "print(avg_epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Art-Photography', 'Biography', 'Business-Finance-Law', 'Childrens-Books', 'Computing', 'Crafts-Hobbies', 'Crime-Thriller', 'Dictionaries-Languages', 'Entertainment', 'Food-Drink', 'Graphic-Novels-Anime-Manga', 'Health', 'History-Archaeology', 'Home-Garden', 'Humour', 'Medical', 'Mind-Body-Spirit', 'Natural-History', 'Personal-Development', 'Poetry-Drama', 'Reference', 'Religion', 'Romance', 'Science-Fiction-Fantasy-Horror', 'Science-Geography', 'Society-Social-Sciences', 'Sport', 'Stationery', 'Teaching-Resources-Education', 'Technology-Engineering', 'Teen-Young-Adult', 'Transport', 'Travel-Holiday-Guides'])\n"
     ]
    }
   ],
   "source": [
    "print(label2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_things import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "i = 0\n",
    "for t, p in zip(true_labels, predictions_labels):\n",
    "    if t == p:\n",
    "        indices.append(i)\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = 'prediction_output'\n",
    "\n",
    "np.savetxt(os.path.join(prediction_output, \"vit_prediction_output.txt\"), np.array(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 of the book cover are matched from the vit model, the next step is to predict books descriptions from nlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photographs are an integral part of our daily ...</td>\n",
       "      <td>Art-Photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Susan Sontag's On Photography is a seminal and...</td>\n",
       "      <td>Art-Photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contemporary Photography and Theory offers an ...</td>\n",
       "      <td>Art-Photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Art and Photography is the first book of its k...</td>\n",
       "      <td>Art-Photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most comprehensive, up-to-date resource fo...</td>\n",
       "      <td>Art-Photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Dear Traveler, Welcome to the WanderStories™ g...</td>\n",
       "      <td>Travel-Holiday-Guides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Action-packed, thrill-filled holidays begin ri...</td>\n",
       "      <td>Travel-Holiday-Guides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Over 2,500 courses covered in detail. Hotels r...</td>\n",
       "      <td>Travel-Holiday-Guides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Insight Guides Great Breaks Guernsey Travel ma...</td>\n",
       "      <td>Travel-Holiday-Guides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>The information in this temporary record is co...</td>\n",
       "      <td>Travel-Holiday-Guides</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                  label\n",
       "0    Photographs are an integral part of our daily ...        Art-Photography\n",
       "1    Susan Sontag's On Photography is a seminal and...        Art-Photography\n",
       "2    Contemporary Photography and Theory offers an ...        Art-Photography\n",
       "3    Art and Photography is the first book of its k...        Art-Photography\n",
       "4    The most comprehensive, up-to-date resource fo...        Art-Photography\n",
       "..                                                 ...                    ...\n",
       "259  Dear Traveler, Welcome to the WanderStories™ g...  Travel-Holiday-Guides\n",
       "260  Action-packed, thrill-filled holidays begin ri...  Travel-Holiday-Guides\n",
       "261  Over 2,500 courses covered in detail. Hotels r...  Travel-Holiday-Guides\n",
       "262  Insight Guides Great Breaks Guernsey Travel ma...  Travel-Holiday-Guides\n",
       "263  The information in this temporary record is co...  Travel-Holiday-Guides\n",
       "\n",
       "[264 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_description = pd.read_csv(os.path.join(DATA_DIR, 'temp_data.csv'))\n",
    "# print(test_description[['volumeInfo.title', 'volumeInfo.description', 'search_term']])\n",
    "test_description_sorted = pd.DataFrame(columns=['text', 'label'])\n",
    "test_description['volumeInfo.description'].fillna(test_description['volumeInfo.title'], inplace=True)\n",
    "test_description_sorted.text = test_description['volumeInfo.description']\n",
    "test_description_sorted.label = test_description['search_term']\n",
    "test_description_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_description_sorted.isna().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_description_sorted.to_csv(os.path.join(DATA_DIR, \"test_data_sorted.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (set_seed,\n",
    "                          TrainingArguments,\n",
    "                          Trainer,\n",
    "                          GPT2Config,\n",
    "                          GPT2Tokenizer,\n",
    "                          AdamW, \n",
    "                          get_linear_schedule_with_warmup,\n",
    "                          GPT2ForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(123)\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "max_length = 200\n",
    "\n",
    "n_labels = len(CATEGORIES)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_path = 'fine_tuned_models_gpt2\\\\model'\n",
    "\n",
    "tokenizer_path = 'fine_tuned_models_gpt2\\\\tokenizer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuraiton...\n",
      "Loading tokenizer...\n",
      "Loading model...\n",
      "Model loaded to `cuda`\n"
     ]
    }
   ],
   "source": [
    "print('Loading configuraiton...')\n",
    "model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=model_path, num_labels=n_labels)\n",
    "\n",
    "# Get model's tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path=tokenizer_path)\n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "# Get the actual model.\n",
    "print('Loading model...')\n",
    "model = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_path, config=model_config)\n",
    "\n",
    "# resize model embedding to match new tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# fix model padding token id\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# Load model to defined device.\n",
    "model.to(device)\n",
    "print('Model loaded to `%s`'%device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class BookDescriptionDataset(Dataset):\n",
    "    def __init__(self, path, use_tokenizer):\n",
    "        if not os.path.exists(path):\n",
    "            raise ValueError('Invalid path variable.')\n",
    "        \n",
    "        book_info = pd.read_csv(path)\n",
    "        self.texts = book_info['text'].values\n",
    "        self.labels = book_info['label'].values\n",
    "        self.n_examples = len(self.labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {'text': self.texts[item],\n",
    "                'label': self.labels[item]}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gpt2ClassificationCollator(object):\n",
    "    def __init__(self, use_tokenizer, labels_encoder, max_sequence_len=None):\n",
    "\n",
    "        # Tokenizer to be used inside the class.\n",
    "        self.use_tokenizer = use_tokenizer\n",
    "        # Check max sequence length.\n",
    "        self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n",
    "        # Label encoder used inside the class.\n",
    "        self.labels_encoder = labels_encoder\n",
    "\n",
    "        return\n",
    "\n",
    "    def __call__(self, sequences):\n",
    "        # Get all texts from sequences list.\n",
    "        texts = [sequence['text'] for sequence in sequences]\n",
    "        # Get all labels from sequences list.\n",
    "        labels = [sequence['label'] for sequence in sequences]\n",
    "        # Encode all labels using label encoder.\n",
    "        labels = [self.labels_encoder[label] for label in labels]\n",
    "        # Call tokenizer on all texts to convert into tensors of numbers with \n",
    "        # appropriate padding.\n",
    "        inputs = self.use_tokenizer(text=texts, return_tensors=\"pt\", padding=True, truncation=True,  max_length=self.max_sequence_len)\n",
    "        # Update the inputs with the associated encoded labels as tensor.\n",
    "        inputs.update({'labels':torch.tensor(labels)})\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ids = {CATEGORIES[i]:i for i in range(len(CATEGORIES))}\n",
    "gpt2_classificaiton_collator = Gpt2ClassificationCollator(use_tokenizer=tokenizer, \n",
    "                                                          labels_encoder=labels_ids, \n",
    "                                                          max_sequence_len=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealing with Test...\n",
      "Created `test_dataset` with 264 examples!\n",
      "Created `eval_dataloader` with 33 batches!\n"
     ]
    }
   ],
   "source": [
    "print('Dealing with Test...')\n",
    "# Create pytorch dataset.\n",
    "test_dataset =  BookDescriptionDataset(path=os.path.join(os.path.join(DATA_DIR, \"test_data_sorted.csv\")), \n",
    "                               use_tokenizer=tokenizer)\n",
    "print('Created `test_dataset` with %d examples!'%len(test_dataset))\n",
    "\n",
    "# Move pytorch dataset into dataloader.\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=gpt2_classificaiton_collator)\n",
    "print('Created `eval_dataloader` with %d batches!'%len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11848/1961525345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrue_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_epoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cuda:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'validation' is not defined"
     ]
    }
   ],
   "source": [
    "true_labels, predictions_labels, avg_epoch_loss = validation(test_dataloader, model, 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19184\\76172820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "print(true_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('miniconda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "927de5e7f191e0eac76bca2691dd3b89a083b9534beeb1b8d06bb75b4c263c81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
